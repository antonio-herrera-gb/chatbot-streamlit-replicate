{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/cabecera.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: **Construye un asistente de IA con Streamlit y Replicate**\n",
    "\n",
    "*Rodrigo Oliver*  \n",
    "*Lead Instructor Bootcamp Data Science Online*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requisitos previos Parte 2 \n",
    "\n",
    "- Una cuenta en [GitHub](https://github.com/signup)\n",
    "- Una cuenta en [Replicate](https://replicate.com) para obtener un API Token\n",
    "- Python 3.8 o superior (si vas a hacer el taller en local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Interfaz conversacional con Streamlit  \n",
    "\n",
    "Adaptado y actualizado de [*streamlit-replicate-app*](https://github.com/sfc-gh-cnantasenamat/streamlit-replicate-app)\n",
    "y de [*llama2-chatbot*](https://github.com/a16z-infra/llama2-chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **¬øQu√© es Streamlit?**\n",
    "\n",
    "Streamlit es un framework gratuito y de c√≥digo abierto para construir y compartir r√°pidamente aplicaciones web de Ciencia de Datos. Es una biblioteca basada en Python y dise√±ada espec√≠ficamente pensando en profesionales del dato.\n",
    "\n",
    "### **¬øPor qu√© Streamlit?**\n",
    "\n",
    "Sencillamente, porque los/las profesionales de la Ciencia de Datos (Data Analysts, Data Scientists, ML Engineers, AI Engineers, etc.) no somos Desarrolladores Web.  \n",
    "\n",
    "Aunque podamos estar familiarizados con otros lenguajes o stacks tecnol√≥gicos (muy recomendable para poder comunicarse eficazmente con otros profesionales), nuestro objetivo no es dominar las herramientas necesarias para crear aplicaciones web.  \n",
    "\n",
    "Sin embargo, eso no significa que nos tengamos que conformar con exponer nuestros proyectos en cuadernos Jupyter. Streamlit nos permite crear aplicaciones de datos con un aspecto muy profesional con unas pocas l√≠neas de c√≥digo, sin tener que depender de la ayuda de otros compa√±eros o departamentos.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Instalaci√≥n\n",
    "Si has llegado hasta aqu√≠, lo m√°s probable es que:\n",
    "- Hayas utilizado el repositorio del taller como plantilla\n",
    "- Est√©s viendo este cuaderno en Codespaces de GitHub\n",
    "\n",
    "En tal caso, Codespaces ya se habr√° ocupado de instalar las dependencias necesarias para el proyecto que se encuentran en el archivo `requirements.txt`\n",
    "\n",
    "Si prefieres realizar el taller en local, te recomendamos crear un entorno virtual e instalar las dependencias necesarias para el desarrollo del proyecto.  \n",
    "\n",
    "Los directorios y archivos contienen la estructura inicial b√°sica del proyecto, incluyendo un directorio `.streamlit` con los archivos `toml` que definen la configuraci√≥n m√≠nima de nuestra app.  \n",
    "\n",
    "[**Si no sabes qu√© es un TOML, pulsa aqu√≠**](https://es.wikipedia.org/wiki/TOML)\n",
    "\n",
    "### Ejecuci√≥n de la aplicaci√≥n\n",
    "\n",
    "En cuanto tu script de Python tenga la configuraci√≥n inicial podr√°s ejecutar tu aplicaci√≥n desde el terminal con:\n",
    "\n",
    "```bash\n",
    "python -m streamlit run chatbot.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 1: Configuraci√≥n inicial**\n",
    "\n",
    "Una vez completada la fase previa de instalaci√≥n, abre el archivo `chatbot.py` en Codespaces o en tu IDE favorito.  \n",
    "\n",
    "Ver√°s que ya contiene la configuraci√≥n inicial. Pero si prefieres trastear tambi√©n puedes crearlo de cero con el siguiente c√≥digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.23.0)\n",
      "Collecting narwhals>=1.14.2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-2.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.20.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.4/10.1 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.7/10.1 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.1/10.1 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.1 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 731.2/731.2 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 2.1/6.9 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.6/6.9 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.2/6.9 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 8.7 MB/s eta 0:00:00\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading narwhals-2.5.0-py3-none-any.whl (407 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, toml, smmap, narwhals, cachetools, pydeck, gitdb, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.5.0 cachetools-6.2.0 gitdb-4.0.12 gitpython-3.1.45 narwhals-2.5.0 pydeck-0.9.1 smmap-5.0.2 streamlit-1.50.0 toml-0.10.2 watchdog-6.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 18:23:02.713 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import replicate\n",
    "import os\n",
    "\n",
    "# C√≥digo refactorizado de https://github.com/sfc-gh-cnantasenamat/streamlit-replicate-app\n",
    "# y https://github.com/a16z-infra/llama2-chatbot\n",
    "\n",
    "# Configuraci√≥n del proyecto\n",
    "APP_NAME = 'My First Chatbot'\n",
    "MODEL_NAME = 'Meta Llama 3 8B Instruct'\n",
    "MODEL_ENDPOINT = 'meta/meta-llama-3-8b-instruct'\n",
    "MODEL_DOC_LINK = 'https://replicate.com/meta/meta-llama-3-8b-instruct'\n",
    "\n",
    "# Configuraci√≥n inicial\n",
    "st.set_page_config(\n",
    "    page_title=APP_NAME, \n",
    "    page_icon=':robot:'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 2: Inicializaci√≥n de variables en el estado de la sesi√≥n**\n",
    "\n",
    "Streamlit utiliza un estado de sesi√≥n para mantener variables entre ejecuciones. Inicializamos las variables que necesitaremos:\n",
    "\n",
    "[**Si quieres aprender m√°s sobre Session State en Streamlit, pulsa aqu√≠**](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.session_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializaci√≥n de variables\n",
    "default_system_prompt = '''You are a helpful assistant.\n",
    "You do not respond as \"User\" or pretend to be \"User\".\n",
    "You only respond once as \"Assistant\".'''\n",
    "\n",
    "default_start_message = 'How may I assist you today?'\n",
    "\n",
    "if 'messages' not in st.session_state:\n",
    "    st.session_state.messages = [{'role': 'assistant', 'content': default_start_message}]\n",
    "if 'system_prompt' not in st.session_state:\n",
    "    st.session_state.system_prompt = default_system_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 3: Barra lateral - Estructura b√°sica y API token**\n",
    "\n",
    "Parece que todos nuestros chatbots favoritos dividen su interfaz en una barra lateral y un espacio principal de conversaci√≥n, as√≠ que podemos inspirarnos en ellos.\n",
    "\n",
    "Streamlit nos permite construir barras laterales con facilidad, comencemos con su estructura b√°sica donde incluiremos la configuraci√≥n del API token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barra lateral\n",
    "with st.sidebar:\n",
    "    st.title(APP_NAME)\n",
    "    \n",
    "    # API token\n",
    "    try:\n",
    "        if st.secrets and 'REPLICATE_API_TOKEN' in st.secrets:\n",
    "            replicate_api_token = st.secrets['REPLICATE_API_TOKEN']\n",
    "            st.success('API token already provided!', icon='‚úÖ')\n",
    "        else:\n",
    "            raise KeyError\n",
    "    except:\n",
    "        replicate_api_token = st.text_input('Enter Replicate API token:', type='password')\n",
    "        if not (replicate_api_token and replicate_api_token.startswith('r8_') and len(replicate_api_token) == 40):\n",
    "            st.warning('Please enter a valid Replicate API token!', icon='‚ö†Ô∏è')\n",
    "            if replicate_api_token:\n",
    "                st.info(\"Replicate tokens start with 'r8_' and are 40 characters long\")\n",
    "        else:\n",
    "            st.success('Proceed to chat!', icon='üëâ')\n",
    "    \n",
    "    if replicate_api_token:\n",
    "        os.environ['REPLICATE_API_TOKEN'] = replicate_api_token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de este punto para ejecutar la aplicaci√≥n es recomendable crear un archivo `secrets.toml` dentro del directorio `.streamlit/`con tu API key de Replicate.\n",
    "\n",
    "Puedes aprovechar el archivo de ejemplo `secrets.example.toml` como base, en su interior ver√°s\n",
    "\n",
    "```toml\n",
    "REPLICATE_API_TOKEN = \"tu_api_token_de_replicate\"\n",
    "```\n",
    "\n",
    "Esto nos permitir√° testear la aplicaci√≥n durante su desarrollo, pero recuerda que **nunca debes subir tus secretos a GitHub**.  \n",
    "\n",
    "Cuando despleguemos nuestro chatbot podr√°s decidir si facilitamos una API token (y asumimos los gastos del chatbot) o dejamos que los usuarios utilicen sus propios API token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 4: Funci√≥n para generar respuestas**\n",
    "\n",
    "De momento dejaremos la barra lateral as√≠, porque queremos chatear con nuestro asistente. \n",
    "\n",
    "Para ello definimos la funci√≥n que se comunicar√° con Replicate para obtener respuestas del modelo. Esta funci√≥n es el coraz√≥n de nuestro chatbot y realiza varias tareas clave:\n",
    "\n",
    "1. **Formatea el historial de conversaci√≥n**:\n",
    "   - Comienza con el System Prompt (instrucciones iniciales para el modelo) y tras ello agrega todo el historial de mensajes con formato \"User:\" y \"Assistant:\".\n",
    "   - Esto es importante porque permite que el modelo tenga contexto completo de la conversaci√≥n.\n",
    "\n",
    "2. **Configura los par√°metros de generaci√≥n**:\n",
    "   - Prepara los par√°metros que controlar√°n el comportamiento del modelo, de momento solo incluiremos el prompt pero recuerda que puedes ajustar par√°metros como temperatura, longitud m√°xima, penalizaci√≥n por repetici√≥n, etc.\n",
    "\n",
    "3. **Transmite la respuesta en tiempo real**:\n",
    "   - Utiliza la funci√≥n `stream` de Replicate para obtener tokens de respuesta gradualmente e implementa un **generador** que permite mostrar la respuesta token por token.\n",
    "   - Esto crea una experiencia m√°s natural donde el usuario ve la respuesta form√°ndose progresivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generaci√≥n de respuestas\n",
    "def generate_response():\n",
    "    conversation_context = f'System: {st.session_state.system_prompt}\\n\\n'\n",
    "    for dict_message in st.session_state.messages:\n",
    "        role = dict_message.get('role', '')\n",
    "        if role in ('user', 'assistant'):\n",
    "            conversation_context += f'{role.capitalize()}: {dict_message[\"content\"]}\\n\\n'\n",
    "    \n",
    "    input_params = {\n",
    "        'prompt': f'{conversation_context}Assistant: '\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        for event in replicate.stream(MODEL_ENDPOINT, input=input_params):\n",
    "            yield str(event)\n",
    "    except replicate.exceptions.ReplicateError as e:\n",
    "        yield f'Replicate API Error: {e}'\n",
    "    except Exception as e:\n",
    "        yield f'Unexpected error: {e}. Please check your connection and API token.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 5: Interfaz de chat**\n",
    "\n",
    "Ahora que tenemos lista la funci√≥n principal de nuestro asistente, creamos la interfaz de chat que mostrar√° los mensajes y permitir√° al usuario interactuar con el chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrada del usuario\n",
    "if prompt := st.chat_input('Type your message here...', disabled=not replicate_api_token):\n",
    "    st.session_state.messages.append({'role': 'user', 'content': prompt})\n",
    "\n",
    "# Mostrar mensajes\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message['role']):\n",
    "        st.write(message['content'])\n",
    "\n",
    "# Generar respuesta\n",
    "if st.session_state.messages and st.session_state.messages[-1]['role'] == 'user':\n",
    "    with st.chat_message('assistant'):\n",
    "        with st.spinner('Thinking...'):\n",
    "            response = generate_response()\n",
    "            full_response = st.write_stream(response)\n",
    "    st.session_state.messages.append({'role': 'assistant', 'content': full_response})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T√©cnicamente, llegados a este punto el c√≥digo es suficiente para hacer funcionar nuestro chatbot, pero creo que le vendr√° bien algo m√°s de funcionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 6: Barra lateral - System Prompt Editable**\n",
    "\n",
    "Dado que hemos hecho tanto hincapi√© en la importancia del System Prompt, ¬øpor qu√© no a√±adir un √°rea de texto con la que poder hacer pruebas m√°s f√°cilmente?\n",
    "\n",
    "Adelante, a√±adimos el √°rea de texto para editar el prompt de sistema y as√≠ poder definir el comportamiento de nuestro chatbot.\n",
    "\n",
    "Importante, para que quede m√°s integrado en la interfaz de nuestra app vamos a incluir este c√≥digo en la barra lateral. Busca su posici√≥n en el archivo base (gu√≠ate por los comentarios) y ten cuidado con las indentaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # System Prompt editable\n",
    "    st.subheader('System Prompt')\n",
    "\n",
    "    def on_system_prompt_change():\n",
    "        st.session_state.system_prompt = st.session_state.system_prompt_textarea\n",
    "\n",
    "    st.text_area(\n",
    "        'Edit the prompt that guides the model:',\n",
    "        value=st.session_state.system_prompt,\n",
    "        height=150,\n",
    "        key='system_prompt_textarea',\n",
    "        on_change=on_system_prompt_change\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 7: Barra lateral - Informaci√≥n del modelo**\n",
    "\n",
    "Parece que la aplicaci√≥n empieza a tener buena pinta, ¬øqu√© os parece si a√±adimos algo de informaci√≥n sobre nuestro querido modelo?.\n",
    "\n",
    "> Recuerda que es totalmente opcional, pero quiz√° esto te haga reflexionar sobre qu√© pasar√≠a si, por ejemplo, quisieramos incluir un desplegable para cambiar el modelo base a nuestro gusto.\n",
    ">\n",
    "> Te animamos a que lo intentes y hagas tus propios cambios en el c√≥digo (despu√©s de terminar el taller).  \n",
    "\n",
    "Recuerda que va en la barra lateral, cuidado con las indentaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Informaci√≥n del modelo\n",
    "    st.subheader('Model')\n",
    "    st.info(f'Using {MODEL_NAME}')\n",
    "    st.markdown(f'üëâ [Learn more about this model]({MODEL_DOC_LINK}) üëà')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 8: Barra lateral - Bot√≥n de limpiar historial**\n",
    "\n",
    "Para terminar nuestro proyecto, vamos a implementar un bot√≥n para limpiar el historial de chat, esto borrar√° los mensajes del estado de sesi√≥n de modo que \"reiniciar√°\" la conversaci√≥n de forma similar a cuando iniciamos un nuevo chat en ChatGPT.\n",
    "\n",
    "Recuerda que es parte de la barra lateral as√≠ que cuidado con las indentaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Bot√≥n para limpiar historial \n",
    "    def clear_chat_history():\n",
    "        st.session_state.messages = [{'role': 'assistant', 'content': default_start_message}]\n",
    "\n",
    "    st.button('Clear Chat', on_click=clear_chat_history, use_container_width=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora s√≠, nuestro proyecto est√° listo para desplegar en la nube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 9: Configuraci√≥n para despliegue**\n",
    "\n",
    "Para desplegar tu aplicaci√≥n en Streamlit Cloud:\n",
    "\n",
    "1. Haz commit de los cambios desde Codespaces (o desde tu equipo si est√°s trabajando el local) a tu repositorio de GitHub, para ello ve al terminal y ejecuta los siguientes comandos:\n",
    "\n",
    "    ```bash\n",
    "    git add .\n",
    "    git commit -m \"C√≥digo chatbot\"\n",
    "    git push\n",
    "    ```\n",
    "\n",
    "2. Con√©ctate a [Streamlit Cloud](https://streamlit.io/cloud) y selecciona la versi√≥n Free. Date de alta usando tu cuenta de GitHub.\n",
    "3. Selecciona tu repositorio, la rama y el archivo principal.\n",
    "4. Configura tus secretos en la interfaz de Streamlit Cloud, solo si quieres y bajo tu responsabilidad (puedes acceder desde el men√∫ de tres puntos de tu aplicaci√≥n).\n",
    "5. Es hora de desplegar tu aplicaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **¬°Felicidades!**  \n",
    "\n",
    "Has creado y desplegado un chatbot b√°sico con Streamlit y Replicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Muy Importante**\n",
    "\n",
    "**Recuerda detener tu entorno de Codespaces** para no incurrir en posibles gastos de facturaci√≥n. Si te deja m√°s tranquil@ tambi√©n puedes eliminar todo el espacio de desarrollo y volver a levantarlo de nuevo m√°s adelante.\n",
    "\n",
    "# **Gracias por vuestra atenci√≥n :)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
