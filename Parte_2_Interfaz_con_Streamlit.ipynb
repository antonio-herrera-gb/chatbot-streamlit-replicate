{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/cabecera.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: **Construye un asistente de IA con Streamlit y Replicate**\n",
    "\n",
    "*Rodrigo Oliver*  \n",
    "*Lead Instructor Bootcamp Data Science Online*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requisitos previos Parte 2 \n",
    "\n",
    "- Una cuenta en [GitHub](https://github.com/signup)\n",
    "- Una cuenta en [Replicate](https://replicate.com) para obtener un API Token\n",
    "- Python 3.8 o superior (si vas a hacer el taller en local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Interfaz conversacional con Streamlit  \n",
    "\n",
    "Adaptado y actualizado de [*streamlit-replicate-app*](https://github.com/sfc-gh-cnantasenamat/streamlit-replicate-app)\n",
    "y de [*llama2-chatbot*](https://github.com/a16z-infra/llama2-chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **¿Qué es Streamlit?**\n",
    "\n",
    "Streamlit es un framework gratuito y de código abierto para construir y compartir rápidamente aplicaciones web de Ciencia de Datos. Es una biblioteca basada en Python y diseñada específicamente pensando en profesionales del dato.\n",
    "\n",
    "### **¿Por qué Streamlit?**\n",
    "\n",
    "Sencillamente, porque los/las profesionales de la Ciencia de Datos (Data Analysts, Data Scientists, ML Engineers, AI Engineers, etc.) no somos Desarrolladores Web.  \n",
    "\n",
    "Aunque podamos estar familiarizados con otros lenguajes o stacks tecnológicos (muy recomendable para poder comunicarse eficazmente con otros profesionales), nuestro objetivo no es dominar las herramientas necesarias para crear aplicaciones web.  \n",
    "\n",
    "Sin embargo, eso no significa que nos tengamos que conformar con exponer nuestros proyectos en cuadernos Jupyter. Streamlit nos permite crear aplicaciones de datos con un aspecto muy profesional con unas pocas líneas de código, sin tener que depender de la ayuda de otros compañeros o departamentos.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Instalación\n",
    "Si has llegado hasta aquí, lo más probable es que:\n",
    "- Hayas utilizado el repositorio del taller como plantilla\n",
    "- Estés viendo este cuaderno en Codespaces de GitHub\n",
    "\n",
    "En tal caso, Codespaces ya se habrá ocupado de instalar las dependencias necesarias para el proyecto que se encuentran en el archivo `requirements.txt`\n",
    "\n",
    "Si prefieres realizar el taller en local, te recomendamos crear un entorno virtual e instalar las dependencias necesarias para el desarrollo del proyecto.  \n",
    "\n",
    "Los directorios y archivos contienen la estructura inicial básica del proyecto, incluyendo un directorio `.streamlit` con los archivos `toml` que definen la configuración mínima de nuestra app.  \n",
    "\n",
    "[**Si no sabes qué es un TOML, pulsa aquí**](https://es.wikipedia.org/wiki/TOML)\n",
    "\n",
    "### Ejecución de la aplicación\n",
    "\n",
    "En cuanto tu script de Python tenga la configuración inicial podrás ejecutar tu aplicación desde el terminal con:\n",
    "\n",
    "```bash\n",
    "python -m streamlit run chatbot.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 1: Configuración inicial**\n",
    "\n",
    "Una vez completada la fase previa de instalación, abre el archivo `chatbot.py` en Codespaces o en tu IDE favorito.  \n",
    "\n",
    "Verás que ya contiene la configuración inicial. Pero si prefieres trastear también puedes crearlo de cero con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.23.0)\n",
      "Collecting narwhals>=1.14.2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-2.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.20.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.4/10.1 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.7/10.1 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.1/10.1 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.1 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 731.2/731.2 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 2.1/6.9 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.6/6.9 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.2/6.9 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 8.7 MB/s eta 0:00:00\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading narwhals-2.5.0-py3-none-any.whl (407 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, toml, smmap, narwhals, cachetools, pydeck, gitdb, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.5.0 cachetools-6.2.0 gitdb-4.0.12 gitpython-3.1.45 narwhals-2.5.0 pydeck-0.9.1 smmap-5.0.2 streamlit-1.50.0 toml-0.10.2 watchdog-6.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 18:23:02.713 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import replicate\n",
    "import os\n",
    "\n",
    "# Código refactorizado de https://github.com/sfc-gh-cnantasenamat/streamlit-replicate-app\n",
    "# y https://github.com/a16z-infra/llama2-chatbot\n",
    "\n",
    "# Configuración del proyecto\n",
    "APP_NAME = 'My First Chatbot'\n",
    "MODEL_NAME = 'Meta Llama 3 8B Instruct'\n",
    "MODEL_ENDPOINT = 'meta/meta-llama-3-8b-instruct'\n",
    "MODEL_DOC_LINK = 'https://replicate.com/meta/meta-llama-3-8b-instruct'\n",
    "\n",
    "# Configuración inicial\n",
    "st.set_page_config(\n",
    "    page_title=APP_NAME, \n",
    "    page_icon=':robot:'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 2: Inicialización de variables en el estado de la sesión**\n",
    "\n",
    "Streamlit utiliza un estado de sesión para mantener variables entre ejecuciones. Inicializamos las variables que necesitaremos:\n",
    "\n",
    "[**Si quieres aprender más sobre Session State en Streamlit, pulsa aquí**](https://docs.streamlit.io/develop/api-reference/caching-and-state/st.session_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de variables\n",
    "default_system_prompt = '''You are a helpful assistant.\n",
    "You do not respond as \"User\" or pretend to be \"User\".\n",
    "You only respond once as \"Assistant\".'''\n",
    "\n",
    "default_start_message = 'How may I assist you today?'\n",
    "\n",
    "if 'messages' not in st.session_state:\n",
    "    st.session_state.messages = [{'role': 'assistant', 'content': default_start_message}]\n",
    "if 'system_prompt' not in st.session_state:\n",
    "    st.session_state.system_prompt = default_system_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 3: Barra lateral - Estructura básica y API token**\n",
    "\n",
    "Parece que todos nuestros chatbots favoritos dividen su interfaz en una barra lateral y un espacio principal de conversación, así que podemos inspirarnos en ellos.\n",
    "\n",
    "Streamlit nos permite construir barras laterales con facilidad, comencemos con su estructura básica donde incluiremos la configuración del API token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barra lateral\n",
    "with st.sidebar:\n",
    "    st.title(APP_NAME)\n",
    "    \n",
    "    # API token\n",
    "    try:\n",
    "        if st.secrets and 'REPLICATE_API_TOKEN' in st.secrets:\n",
    "            replicate_api_token = st.secrets['REPLICATE_API_TOKEN']\n",
    "            st.success('API token already provided!', icon='✅')\n",
    "        else:\n",
    "            raise KeyError\n",
    "    except:\n",
    "        replicate_api_token = st.text_input('Enter Replicate API token:', type='password')\n",
    "        if not (replicate_api_token and replicate_api_token.startswith('r8_') and len(replicate_api_token) == 40):\n",
    "            st.warning('Please enter a valid Replicate API token!', icon='⚠️')\n",
    "            if replicate_api_token:\n",
    "                st.info(\"Replicate tokens start with 'r8_' and are 40 characters long\")\n",
    "        else:\n",
    "            st.success('Proceed to chat!', icon='👉')\n",
    "    \n",
    "    if replicate_api_token:\n",
    "        os.environ['REPLICATE_API_TOKEN'] = replicate_api_token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de este punto para ejecutar la aplicación es recomendable crear un archivo `secrets.toml` dentro del directorio `.streamlit/`con tu API key de Replicate.\n",
    "\n",
    "Puedes aprovechar el archivo de ejemplo `secrets.example.toml` como base, en su interior verás\n",
    "\n",
    "```toml\n",
    "REPLICATE_API_TOKEN = \"tu_api_token_de_replicate\"\n",
    "```\n",
    "\n",
    "Esto nos permitirá testear la aplicación durante su desarrollo, pero recuerda que **nunca debes subir tus secretos a GitHub**.  \n",
    "\n",
    "Cuando despleguemos nuestro chatbot podrás decidir si facilitamos una API token (y asumimos los gastos del chatbot) o dejamos que los usuarios utilicen sus propios API token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 4: Función para generar respuestas**\n",
    "\n",
    "De momento dejaremos la barra lateral así, porque queremos chatear con nuestro asistente. \n",
    "\n",
    "Para ello definimos la función que se comunicará con Replicate para obtener respuestas del modelo. Esta función es el corazón de nuestro chatbot y realiza varias tareas clave:\n",
    "\n",
    "1. **Formatea el historial de conversación**:\n",
    "   - Comienza con el System Prompt (instrucciones iniciales para el modelo) y tras ello agrega todo el historial de mensajes con formato \"User:\" y \"Assistant:\".\n",
    "   - Esto es importante porque permite que el modelo tenga contexto completo de la conversación.\n",
    "\n",
    "2. **Configura los parámetros de generación**:\n",
    "   - Prepara los parámetros que controlarán el comportamiento del modelo, de momento solo incluiremos el prompt pero recuerda que puedes ajustar parámetros como temperatura, longitud máxima, penalización por repetición, etc.\n",
    "\n",
    "3. **Transmite la respuesta en tiempo real**:\n",
    "   - Utiliza la función `stream` de Replicate para obtener tokens de respuesta gradualmente e implementa un **generador** que permite mostrar la respuesta token por token.\n",
    "   - Esto crea una experiencia más natural donde el usuario ve la respuesta formándose progresivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de respuestas\n",
    "def generate_response():\n",
    "    conversation_context = f'System: {st.session_state.system_prompt}\\n\\n'\n",
    "    for dict_message in st.session_state.messages:\n",
    "        role = dict_message.get('role', '')\n",
    "        if role in ('user', 'assistant'):\n",
    "            conversation_context += f'{role.capitalize()}: {dict_message[\"content\"]}\\n\\n'\n",
    "    \n",
    "    input_params = {\n",
    "        'prompt': f'{conversation_context}Assistant: '\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        for event in replicate.stream(MODEL_ENDPOINT, input=input_params):\n",
    "            yield str(event)\n",
    "    except replicate.exceptions.ReplicateError as e:\n",
    "        yield f'Replicate API Error: {e}'\n",
    "    except Exception as e:\n",
    "        yield f'Unexpected error: {e}. Please check your connection and API token.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 5: Interfaz de chat**\n",
    "\n",
    "Ahora que tenemos lista la función principal de nuestro asistente, creamos la interfaz de chat que mostrará los mensajes y permitirá al usuario interactuar con el chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrada del usuario\n",
    "if prompt := st.chat_input('Type your message here...', disabled=not replicate_api_token):\n",
    "    st.session_state.messages.append({'role': 'user', 'content': prompt})\n",
    "\n",
    "# Mostrar mensajes\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message['role']):\n",
    "        st.write(message['content'])\n",
    "\n",
    "# Generar respuesta\n",
    "if st.session_state.messages and st.session_state.messages[-1]['role'] == 'user':\n",
    "    with st.chat_message('assistant'):\n",
    "        with st.spinner('Thinking...'):\n",
    "            response = generate_response()\n",
    "            full_response = st.write_stream(response)\n",
    "    st.session_state.messages.append({'role': 'assistant', 'content': full_response})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Técnicamente, llegados a este punto el código es suficiente para hacer funcionar nuestro chatbot, pero creo que le vendrá bien algo más de funcionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 6: Barra lateral - System Prompt Editable**\n",
    "\n",
    "Dado que hemos hecho tanto hincapié en la importancia del System Prompt, ¿por qué no añadir un área de texto con la que poder hacer pruebas más fácilmente?\n",
    "\n",
    "Adelante, añadimos el área de texto para editar el prompt de sistema y así poder definir el comportamiento de nuestro chatbot.\n",
    "\n",
    "Importante, para que quede más integrado en la interfaz de nuestra app vamos a incluir este código en la barra lateral. Busca su posición en el archivo base (guíate por los comentarios) y ten cuidado con las indentaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # System Prompt editable\n",
    "    st.subheader('System Prompt')\n",
    "\n",
    "    def on_system_prompt_change():\n",
    "        st.session_state.system_prompt = st.session_state.system_prompt_textarea\n",
    "\n",
    "    st.text_area(\n",
    "        'Edit the prompt that guides the model:',\n",
    "        value=st.session_state.system_prompt,\n",
    "        height=150,\n",
    "        key='system_prompt_textarea',\n",
    "        on_change=on_system_prompt_change\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 7: Barra lateral - Información del modelo**\n",
    "\n",
    "Parece que la aplicación empieza a tener buena pinta, ¿qué os parece si añadimos algo de información sobre nuestro querido modelo?.\n",
    "\n",
    "> Recuerda que es totalmente opcional, pero quizá esto te haga reflexionar sobre qué pasaría si, por ejemplo, quisieramos incluir un desplegable para cambiar el modelo base a nuestro gusto.\n",
    ">\n",
    "> Te animamos a que lo intentes y hagas tus propios cambios en el código (después de terminar el taller).  \n",
    "\n",
    "Recuerda que va en la barra lateral, cuidado con las indentaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Información del modelo\n",
    "    st.subheader('Model')\n",
    "    st.info(f'Using {MODEL_NAME}')\n",
    "    st.markdown(f'👉 [Learn more about this model]({MODEL_DOC_LINK}) 👈')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 8: Barra lateral - Botón de limpiar historial**\n",
    "\n",
    "Para terminar nuestro proyecto, vamos a implementar un botón para limpiar el historial de chat, esto borrará los mensajes del estado de sesión de modo que \"reiniciará\" la conversación de forma similar a cuando iniciamos un nuevo chat en ChatGPT.\n",
    "\n",
    "Recuerda que es parte de la barra lateral así que cuidado con las indentaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Botón para limpiar historial \n",
    "    def clear_chat_history():\n",
    "        st.session_state.messages = [{'role': 'assistant', 'content': default_start_message}]\n",
    "\n",
    "    st.button('Clear Chat', on_click=clear_chat_history, use_container_width=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora sí, nuestro proyecto está listo para desplegar en la nube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paso 9: Configuración para despliegue**\n",
    "\n",
    "Para desplegar tu aplicación en Streamlit Cloud:\n",
    "\n",
    "1. Haz commit de los cambios desde Codespaces (o desde tu equipo si estás trabajando el local) a tu repositorio de GitHub, para ello ve al terminal y ejecuta los siguientes comandos:\n",
    "\n",
    "    ```bash\n",
    "    git add .\n",
    "    git commit -m \"Código chatbot\"\n",
    "    git push\n",
    "    ```\n",
    "\n",
    "2. Conéctate a [Streamlit Cloud](https://streamlit.io/cloud) y selecciona la versión Free. Date de alta usando tu cuenta de GitHub.\n",
    "3. Selecciona tu repositorio, la rama y el archivo principal.\n",
    "4. Configura tus secretos en la interfaz de Streamlit Cloud, solo si quieres y bajo tu responsabilidad (puedes acceder desde el menú de tres puntos de tu aplicación).\n",
    "5. Es hora de desplegar tu aplicación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **¡Felicidades!**  \n",
    "\n",
    "Has creado y desplegado un chatbot básico con Streamlit y Replicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Muy Importante**\n",
    "\n",
    "**Recuerda detener tu entorno de Codespaces** para no incurrir en posibles gastos de facturación. Si te deja más tranquil@ también puedes eliminar todo el espacio de desarrollo y volver a levantarlo de nuevo más adelante.\n",
    "\n",
    "# **Gracias por vuestra atención :)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
